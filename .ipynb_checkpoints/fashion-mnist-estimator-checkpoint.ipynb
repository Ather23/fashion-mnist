{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:29.637422Z",
     "start_time": "2018-11-18T17:08:29.627864Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.225794Z",
     "start_time": "2018-11-18T17:08:29.643649Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "fashion_mnist = input_data.read_data_sets(\"data/fashion\",\n",
    "                                          one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.231487Z",
     "start_time": "2018-11-18T17:08:30.227959Z"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.236813Z",
     "start_time": "2018-11-18T17:08:30.233096Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training set (images) shape: {shape}\".format(shape=fashion_mnist.train.images.shape))\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=fashion_mnist.test.images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.241432Z",
     "start_time": "2018-11-18T17:08:30.238791Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = fashion_mnist.train.images.reshape(fashion_mnist.train.images.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Checking if classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.369208Z",
     "start_time": "2018-11-18T17:08:30.243158Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(fashion_mnist.train.labels,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.375930Z",
     "start_time": "2018-11-18T17:08:30.370911Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_conv_layer(input_x, num_channels,filter_size,num_filter):\n",
    "    weights = create_weights(shape=[filter_size,\n",
    "                                    filter_size, num_channels,\n",
    "                                    num_filter])\n",
    "    biases = create_biases(num_filter)\n",
    "    layer = tf.nn.conv2d(input=input_x,\n",
    "                        filter=weights,\n",
    "                        strides=[1,1,1,1],\n",
    "                        padding = 'SAME')\n",
    "    layer = tf.add(layer,biases)    \n",
    "    layer = maxpool(layer)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer\n",
    "\n",
    "\n",
    "def fc_layer(input,num_inputs,num_outputs):   \n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(size=num_outputs)\n",
    "    layer = tf.matmul(input,weights)+biases\n",
    "    return layer\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    return tf.contrib.layers.flatten(layer)\n",
    "\n",
    "def maxpool(x,k=2):\n",
    "    return tf.nn.max_pool(x,ksize=[1,k,k,1],\n",
    "                          strides = [1,k,k,1],padding='SAME')\n",
    "    \n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    " \n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.389161Z",
     "start_time": "2018-11-18T17:08:30.378205Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_fn(features,labels,mode,params):\n",
    "    x = features\n",
    "    y=labels\n",
    "\n",
    "    writer =tf.summary.FileWriter(\"./summary\")\n",
    "    accuracy_summary = tf.Summary()\n",
    "    cost_summary = tf.Summary()\n",
    "    layer = create_conv_layer(x,num_channels=1,filter_size=10,num_filter=2)\n",
    "    layer = create_conv_layer(layer,2,5,2)\n",
    "    layer = create_conv_layer(layer,2,5,2)\n",
    "    layer = create_conv_layer(layer,2,5,2)\n",
    "    layer=flatten_layer(layer)\n",
    "    layer=flatten_layer(layer)\n",
    "    layer=flatten_layer(layer)\n",
    "    layer=flatten_layer(layer)\n",
    "   \n",
    "    final = fc_layer(layer,8,10)\n",
    "    \n",
    "    y_pred = tf.nn.softmax(final,name=\"y_pred\")\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions =y_pred\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    \n",
    "    y_pred_cls = tf.argmax(y_pred,dimension=1)    \n",
    "    with tf.name_scope(\"cost_function\") as scope:    \n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "             logits=y_pred,labels=y)\n",
    "        cost = tf.reduce_mean(cross_entropy)\n",
    "        cost_summary = tf.summary.scalar(\"cost\",cost)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        corr_pred = tf.equal(\n",
    "            tf.argmax(y,1),\n",
    "           y_pred_cls\n",
    "        )\n",
    "        acc = tf.reduce_mean(tf.cast(corr_pred,tf.float32))\n",
    "        accuracy_summary = tf.summary.scalar(\"tr_acc\",acc)\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": tf.metrics.accuracy( tf.argmax(y,1), y_pred_cls)\n",
    "        }\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(mode,loss=cost,eval_metric_ops=metrics)\n",
    "\n",
    "\n",
    "    with tf.name_scope(\"training\") as scope:\n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=params[\"learning_rate\"]).minimize(cost)\n",
    " \n",
    "    logging_hook = tf.train.LoggingTensorHook({\"loss\" : cost}, every_n_iter=1)\n",
    "    \n",
    "    summary_hook = tf.train.SummarySaverHook(\n",
    "    save_steps =1,\n",
    "    output_dir='./summary',\n",
    "    summary_op=tf.summary.merge_all())\n",
    "        \n",
    "    spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=cost,\n",
    "            train_op=optimizer,\n",
    "            eval_metric_ops=metrics,\n",
    "        training_hooks=[summary_hook])\n",
    "    \n",
    "    return spec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T06:56:29.806872Z",
     "start_time": "2018-11-18T06:56:29.792310Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:08:30.395487Z",
     "start_time": "2018-11-18T17:08:30.390711Z"
    },
    "code_folding": [
     0,
     19
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    images = fashion_mnist.train.images\n",
    "    labels =fashion_mnist.train.labels\n",
    "    print(len(images))\n",
    "    \n",
    "    labels = tf.convert_to_tensor(labels) \n",
    "    labels =tf.one_hot(labels,depth=10)\n",
    "\n",
    "    data = images.reshape(images.shape[0],28,28,1)\n",
    "    data = tf.convert_to_tensor(data)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (data, labels))\n",
    "    \n",
    "    dataset=dataset.batch(100)\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()    \n",
    "    return features,labels\n",
    "\n",
    "\n",
    "def eval_fn():\n",
    "    images = fashion_mnist.test.images\n",
    "    labels =fashion_mnist.test.labels\n",
    "    \n",
    "    labels = tf.convert_to_tensor(labels) \n",
    "    labels =tf.one_hot(labels,depth=10)\n",
    "\n",
    "    data = images.reshape(images.shape[0],28,28,1)\n",
    "    data = tf.convert_to_tensor(data)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (data, labels))\n",
    "\n",
    "    dataset=dataset.batch(100)\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    \n",
    "    return features,labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:10:01.602543Z",
     "start_time": "2018-11-18T17:08:30.397467Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_rate=0.1\n",
    "for epoch in range(0,10):\n",
    "    l_rate=0.1/10\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    params = {\"learning_rate\": l_rate}\n",
    "    run_config = tf.estimator.RunConfig()\n",
    "    model = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                   params=params,\n",
    "                                   config = run_config,\n",
    "#                                    warm_start_from=\"./summary\",\n",
    "                                   model_dir=\"./summary\")\n",
    "    model.train(input_fn=input_fn,steps=10)\n",
    "    model.evaluate(input_fn=eval_fn,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:10:01.605991Z",
     "start_time": "2018-11-18T17:08:29.675Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_input(images):    \n",
    "    data = images.reshape(images.shape[0],28,28,1)\n",
    "    data = tf.convert_to_tensor(data)\n",
    "    dataset = tf.data.Dataset.from_tensors(data)    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:10:01.606991Z",
     "start_time": "2018-11-18T17:08:29.677Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_images = fashion_mnist.test.images[0:2]\n",
    "l_labels = fashion_mnist.test.labels[0:2]\n",
    "predictions = model.predict(input_fn=lambda: pred_input(p_images))\n",
    "for idx,p in enumerate(list(predictions)):\n",
    "    print(\"Expected:\",l_labels[idx])\n",
    "    print(\"Probabilities:\",p)\n",
    "    print(\"Predicted class: \",np.argsort(p)[::-1][0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:10:01.607982Z",
     "start_time": "2018-11-18T17:08:29.678Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = fashion_mnist.test.images[0].reshape(28,28)\n",
    "print(sample.shape)\n",
    "plt.imshow(sample,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T17:10:01.608815Z",
     "start_time": "2018-11-18T17:08:29.680Z"
    }
   },
   "outputs": [],
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
